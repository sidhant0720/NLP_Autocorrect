# -*- coding: utf-8 -*-
"""NLP_Autocorrrect.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11TqhtsXFAoMtNZRucSym4h5mgHvP4PlR
"""

import re
from collections import Counter
import numpy as np
import pandas as pd

def process_data(file_name):
    words = []
    fh = open(file_name)
    for line in fh:
        line_lower = line.lower()
        w = re.findall(r'\w+', line_lower)
        words+=w
    return words

word_l = process_data('shakespeare.txt') #Replace with shakespeare.txt
vocab = set(word_l) 
print(f"The first ten words in the text are: \n{word_l[0:10]}")
print(f"There are {len(vocab)} unique words in the vocabulary.")

def get_count(word_l):  
    word_count_dict = {}
    word_count_dict=Counter(word_l)
    return word_count_dict

word_count_dict = get_count(word_l)

def get_probs(word_count_dict):
    probs = {}
    M = sum([freq for freq in word_count_dict.values()]) 
    for word,count in word_count_dict.items():
        probs[word] = count/M
    return probs

probs = get_probs(word_count_dict)

def delete_letter(word, verbose=False):   
    delete_l = []
    split_l = []
    split_l = [(word[0:i],word[i:]) for i in range(len(word)+1)]
    delete_l = [L+R[1:] for L,R in split_l if R]
    if verbose: print(f"input word {word}, \nsplit_l = {split_l}, \ndelete_l = {delete_l}")
    return delete_l


def switch_letter(word, verbose=False):
    switch_l = []
    split_l = []

    split_l = [(word[0:i],word[i:]) for i in range(len(word)+1)]
    switch_l = [ (L[:-1] + R[0] + L[-1] + R[1:]) for L,R in split_l if R and L]
  
    if verbose: print(f"Input word = {word} \nsplit_l = {split_l} \nswitch_l = {switch_l}") 
    
    return switch_l

switch_word_l = switch_letter(word="eta",
                         verbose=True)

def replace_letter(word, verbose=False):   
    letters = 'abcdefghijklmnopqrstuvwxyz'
    replace_l = []
    split_l = []

    split_l = [(word[0:i],word[i:]) for i in range(len(word)+1)]
    replace_l = [(L[:-1]+letters[i]+R) for L,R in split_l if L for i in range(len(letters))]
    replace_set= set(replace_l)
    if(word != ''):
        replace_set.remove(word)

    replace_l = sorted(list(replace_set))
    
    if verbose: print(f"Input word = {word} \nsplit_l = {split_l} \nreplace_l {replace_l}")   
    
    return replace_l

replace_l = replace_letter(word='can',
                              verbose=True)

def insert_letter(word, verbose=False):

    letters = 'abcdefghijklmnopqrstuvwxyz'
    insert_l = []
    split_l = []
    
    split_l = [(word[0:i],word[i:]) for i in range(len(word)+1)]
    insert_l = [(L+letters[i]+R) for L,R in split_l for i in range(len(letters))]

    if verbose: print(f"Input word {word} \nsplit_l = {split_l} \ninsert_l = {insert_l}")
    
    return insert_l


def edit_one_letter(word, allow_switches = True):
    
    edit_one_set = set()

    l = delete_letter(word) + switch_letter(word) + replace_letter(word) + insert_letter(word)
    edit_one_set = set(l)

    return edit_one_set

def edit_two_letters(word, allow_switches = True):
    edit_two_set = set()

    first_edit_l = list(edit_one_letter(word))
    for w in first_edit_l:
        edit_two_set = edit_two_set.union(edit_one_letter(w))

    return edit_two_set

def get_corrections(word, probs, vocab, n=2, verbose = False):
    '''
    Input: 
        word: a user entered string to check for suggestions
        probs: a dictionary that maps each word to its probability in the corpus
        vocab: a set containing all the vocabulary
        n: number of possible word corrections you want returned in the dictionary
    Output: 
        n_best: a list of tuples with the most probable n corrected words and their probabilities.
    '''
    suggestions = []
    n_best = []

    s = list(vocab.intersection(set([word]))) or list(vocab.intersection(edit_one_letter(word))) or list(vocab.intersection(edit_two_letters(word)))
    suggestions = s
    best_words = {w:probs[w] for w in suggestions}
    c = Counter(best_words)

    
    n_best = c.most_common(n)
    
    if verbose: print("entered word = ", word, "\nsuggestions = ", suggestions)

    return n_best

"""Guess Incorrect Word"""

my_word = 'mountane' 
tmp_corrections = get_corrections(my_word, probs, vocab, 2, verbose=True)
for i, word_prob in enumerate(tmp_corrections):
    print(f"word {i}: {word_prob[0]}, probability {word_prob[1]:.6f}")

print(f"data type of corrections {type(tmp_corrections)}")

